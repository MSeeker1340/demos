/* Generated by autotuner.py */
/* tile width = 16, loop unroll = True */
__global__ void matmul(float *M, float *N, float *P, int Width)
{
    // Compute M * N and store result in P
    // M and N are Width * Width matrices
    __shared__ float Ms[16][16];
    __shared__ float Ns[16][16];
    int tx = threadIdx.x;
    int ty = threadIdx.y;
    int Row = blockIdx.y * 16 + ty;
    int Col = blockIdx.x * 16 + tx;

    float Pvalue = 0.0f;
    for (int ph = 0; ph < ceil(Width / (float)16); ++ph)
    {
        // Cooperatively load tile into shared memory
        if (Row < Width && ph*16 + tx < Width)
        {
            Ms[ty][tx] = M[Row*Width + ph*16 + tx];
        }
        else
        {
            Ms[ty][tx] = 0.0f;
        }
        if (Col < Width && ph*16 + ty < Width)
        {
            Ns[ty][tx] = N[(ph*16 + ty)*Width + Col];
        }
        else
        {
            Ns[ty][tx] = 0.0f;
        }
        __syncthreads();

        Pvalue += Ms[ty][0] * Ns[0][tx];
        Pvalue += Ms[ty][1] * Ns[1][tx];
        Pvalue += Ms[ty][2] * Ns[2][tx];
        Pvalue += Ms[ty][3] * Ns[3][tx];
        Pvalue += Ms[ty][4] * Ns[4][tx];
        Pvalue += Ms[ty][5] * Ns[5][tx];
        Pvalue += Ms[ty][6] * Ns[6][tx];
        Pvalue += Ms[ty][7] * Ns[7][tx];
        Pvalue += Ms[ty][8] * Ns[8][tx];
        Pvalue += Ms[ty][9] * Ns[9][tx];
        Pvalue += Ms[ty][10] * Ns[10][tx];
        Pvalue += Ms[ty][11] * Ns[11][tx];
        Pvalue += Ms[ty][12] * Ns[12][tx];
        Pvalue += Ms[ty][13] * Ns[13][tx];
        Pvalue += Ms[ty][14] * Ns[14][tx];
        Pvalue += Ms[ty][15] * Ns[15][tx];
        
        __syncthreads();
    }

    if (Row < Width && Col < Width)
    {
        P[Row*Width + Col] = Pvalue;
    }
}
